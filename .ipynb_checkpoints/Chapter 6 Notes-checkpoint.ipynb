{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6- Memory Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **memory system** is a hierarchy of storage devices with different capacities, costs and access times. Small, fast **cache memories** nearby the CPU act as staging areas for data and instruction stored in main memory. Main memory stages stored in large disks are staging areas for data stored in networks.  \n",
    "**If you can understand how a system moves data up and down the memory hierarchy, then you can write your application programs so that their data items are stored higher in the hierarchy so that the CPU can access them faster**.  \n",
    "This idea centers around an idea known as **locality**. Programs with good locality tend to access the same set of data over and over or they access nearby items. They also tend to access data from upper levels of memory, and thus run faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Storage Technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Random Access Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Access Memory (RAM)** comes in two varieties, static and dynamic.  \n",
    "**Static RAM (SRAM)** is faster and more expensive. It is used for cache memories, both on and off the CPU chip.  \n",
    "**Dynamic RAM (DRAM)** is slower and cheaper. It is used for the main memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRAM stores each bit in a **bistable** memory table. Each cell is implemented with a six transistor circuit, which can have one of either two states.   Theoretically, there can be a **metastable state** where the pendulum is directly up, but the smallest disturbance will cause a fall.    \n",
    "Due to the bistable nature of SRAM, the memory cell will retain its value indefinitely even with disturbances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRAM stores each bit as charge on a capacitor. DRAM storage can be very dense, each cell consists of a capacitor and a transistor. The DRAM cell is very sensitive to any distrubance. Once disturbed, it will never recover. Various sources of leakage can cause DRAM to lose its charge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells in a DRAM chip are partitioned into d supercells, each consisting of w DRAM cells. A dxw DRAM stores a total of dw bits of information.  \n",
    "The supercells are organized as a rectangular array with r rows and c columns. rc = d. Each supercell has an address of the form (i,j) where i is the row and j is the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each DRAM chip is connected to circuitry known as the **memory controller** which can transfer w bits to and from each chip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRAM chips are packaged in **memory modules** that plug into expansion slots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRAM and SRAMS are **volatile** in the sense that they lose their information if their supply voltage is turned off. **Nonvolatile memories** retain their information even when they are powered off. They are mostly referred to as ROMs (Read only memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data flows back and forth between the processor and DRAM memory over shared electrical condiuts called buses. Each transfer of data between CPU and memory is accomplished with a series of steps called a **bus transaction**.  \n",
    "A read transaction transfers data from the main memory to the CPU. A write transaction transfers data from the CPU to the main memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Disk Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disks** are storage devices that hold enormous amounts of data.   \n",
    "Disks are constructed from **platters**, which each consist of two sides, or **surfaces**. A rotating **spindle** in the center of the paltter spins at a fixed rotational rate. Each surface has a collectino of cocentric rings called **tracks**. Each tracks are partitioned into a collection of **sectors**. Each sector contains an equal number of data bits encoded into the magnetic material in the sector. Sectors are separated by **gaps** where no data bits are stored. Gaps store formatting bits that identify the sectors.  \n",
    "A disk consists of one or more platters stacked on each other. These will sometimes be referred to as rotating disks to distinguish them from SSDs which have no moving parts.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum number of bits that can be recorded by the disk is known as the **maximum capacity**. This is determined by the following:  \n",
    "**Recording density**: The number of bits that can be squeezed into a one inch segment of a track.   \n",
    "**Track density**: The number of tracks that can be squeezed into a one inch segment of the radius.   \n",
    "**Areal density**: The product of the recording density and track density.   \n",
    "As areal density increases, the gaps between sectors become pretty large. The modern solution is to use a technique called **multiple zone recording**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The capacity of the disk is given by the following formula:   \n",
    "(bytes/sector) x (number of sectors/track) x (tracks/surface) x (surfaces/platter) x (platters/disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disks read and write data in sector size blocks. The access time for a sector has three main components: seek time, rotational latency and transfer time.   \n",
    "**Seek time**: To read the contents of a target time, the arm first positions the head over the track that contains the sector. The time required to position the arm is known as the seek time.   \n",
    "**Rotational Latency**: Once the head is in position, the drive waits for the first bit of the target sector to pass under the head. The average rotational latency is half of T(max rotation). T(max rotation) can be calculated as follows:   \n",
    "T(max rotation) + (1/RPM) x (60 seconds/min)   \n",
    "**Transfer time**: When the first bit of the target sector is under the head, the drive can begin to read or write contents of the sector. The transfer time on the sector depends on the ratational speed and number of sectors in the track. It can be found with this equation:  \n",
    "T(avg transfer) = (1/RPM) x (1/avg sectors/track) x (60seconds/min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 6.1.3 Solid State Disks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solid state disks is a storage technology based on flash memory. In SSDs, reading is faster than writing, which is caused by a property of flash memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Locality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well written programs have good **locality** which means that they tend to reference data items that are near each other or have been recently referenced.  \n",
    "There are two types of locality:  \n",
    "**Temporal locality**: This is where a memory that is referenced once is likely to be referenced multiple times inthe near future.   \n",
    "**Spatial Locality**: This is where a memory location is referenced once, then a program is likely to reference a nearby memory location in the near future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Locality of References to Program Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Stride-1 Reference Pattern** is a sequential reference pattern (i.e. in an array every element is visited sequentially).   \n",
    "Visiting every kth element is called a **stride-k reference pattern**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Locality of Instruction Fetches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the program instructions are stored in memory and must be fetched, we can also evaluate the locality of a program with respect to the instruction fetches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Summary of Locality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programs that repeatedly reference the same variable enjoy good temporal locality.   \n",
    "For programs with stride-k reference patterns, the smaller the stride, the better the spatial locality. Programs that hop around memory with large strides have poor spatial locality.  \n",
    "Loops have good temporal and spatial locality. The smaller the loop body and the greater the number of loop iterations, the better the locality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 The Memory Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 Writing Cache-Friendly code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmers try to write code that is cache friendly, so the basic approach is to:   \n",
    "**Make the common case go fast**: Programs spend most of the time on a few core functions. Focus on the inner loops of the core functions.   \n",
    "**Minimize the number of cache misses in the loop**: Loops with better miss rates will run faster assuming all other things being equal (i.e. # of loop stores and loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Higher miss rates can have a significant impact on the running time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
